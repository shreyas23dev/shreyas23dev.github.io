# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FFKhoP6pR6DVYaM2eQ5u_xeyChs94PVO
"""

# -*- coding: utf-8 -*-
"""CVSS->PSSS Anvitha

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_qlnbNPCOvPmkd1Bchur33z2KMcvuLtZ
"""

from google.colab import files
uploaded = files.upload()  # choose your nvdcve-1.1-2024.json.gz file

!pip install pandas
import pandas as pd
import json, gzip

import requests, json, pandas as pd, os

filename = "nvdcve-2.0-modified.json"  # your uploaded file

if not os.path.exists(filename):
    print(f"Error: File not found: {filename}")
else:
    with open(filename, 'r', encoding='utf-8') as f:
        data = json.load(f)

    records = []
    for item in data.get("vulnerabilities", []):
        cve = item.get("cve", {})
        cve_id = cve.get("id")
        description = cve.get("descriptions", [])
        desc = description[0].get("value") if description else None

        # Extract CVSS v3.1 metrics (if available)
        av=ac=pr=ui=s=c=i=a=score=None
        metrics_data = cve.get("metrics", {})
        if "cvssMetricV31" in metrics_data:
            cvss_entry = metrics_data["cvssMetricV31"][0]  # take the first entry
            m = cvss_entry.get("cvssData", {})
            av, ac, pr, ui, s = (
                m.get("attackVector"),
                m.get("attackComplexity"),
                m.get("privilegesRequired"),
                m.get("userInteraction"),
                m.get("scope"),
            )
            c, i, a = (
                m.get("confidentialityImpact"),
                m.get("integrityImpact"),
                m.get("availabilityImpact"),
            )
            score = m.get("baseScore")

        records.append({
            "cve_id": cve_id,
            "cve_text": desc,
            "AV": av,
            "AC": ac,
            "PR": pr,
            "UI": ui,
            "S": s,
            "C": c,
            "I": i,
            "A": a,
            "CVSS_base": score
        })

    df = pd.DataFrame(records)
    print("Parsed CVEs:", len(df))
    display(df.head(10))

# Check dataset size and columns
print("Dataset shape:", df.shape)
print("\nColumns:", df.columns.tolist())

# Count missing values per column
print("\nMissing values per column:")
print(df.isna().sum())

# Quick stats for CVSS scores
print("\nCVSS base score distribution:")
print(df["CVSS_base"].describe())

# Show a random sample of 5 rows
df.sample(5)

# Split into labeled vs unlabeled
df_labeled = df.dropna(subset=["CVSS_base"]).reset_index(drop=True)
df_unlabeled = df[df["CVSS_base"].isna()].reset_index(drop=True)

print("Labeled set size:", df_labeled.shape)
print("Unlabeled set size:", df_unlabeled.shape)

# Save for reuse
df_labeled.to_csv("nvd_labeled.csv", index=False)
df_unlabeled.to_csv("nvd_unlabeled.csv", index=False)
print("âœ… Cleaned datasets saved as CSV")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import f1_score, classification_report

# Load the labeled dataset
df_labeled = pd.read_csv("nvd_labeled.csv")

# Define target CVSS metrics
labels = ["AV","AC","PR","UI","S","C","I","A"]
text_col = "cve_text"

# Function to make a classifier for one metric
def make_head(target):
    return Pipeline([
        ("tfidf", TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.9)),
        ("clf", LogisticRegression(max_iter=300, class_weight="balanced"))
    ])

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    df_labeled[text_col], df_labeled[labels],
    test_size=0.2, random_state=42, stratify=df_labeled["AV"].dropna()
)

# Train one classifier per metric
heads = {t: make_head(t).fit(X_train, y_train[t]) for t in labels}

# Predictions
preds = {t: heads[t].predict(X_test) for t in labels}

# Evaluate
for t in labels:
    print(f"\n===== {t} =====")
    print(classification_report(y_test[t], preds[t], zero_division=0))

import matplotlib.pyplot as plt

f1_scores = {}
for t in labels:
    f1 = f1_score(y_test[t], preds[t], average="macro", zero_division=0)
    f1_scores[t] = f1
    print(f"{t}: Macro F1 = {f1:.3f}")

# Bar chart
plt.figure(figsize=(8,5))
plt.bar(f1_scores.keys(), f1_scores.values())
plt.title("Macro F1-score per CVSS Metric")
plt.ylabel("F1-score")
plt.ylim(0,1)
plt.show()

# Load the unlabeled dataset
df_unlabeled = pd.read_csv("nvd_unlabeled.csv")

# Predict CVSS metrics from text
preds_unlabeled = {}
for t in labels:
    preds_unlabeled[t] = heads[t].predict(df_unlabeled["cve_text"])

# Add predictions to DataFrame
for t in labels:
    df_unlabeled[t] = preds_unlabeled[t]

# Save enriched dataset
df_unlabeled.to_csv("nvd_unlabeled_predicted.csv", index=False)

print("âœ… Predicted CVSS vectors for unlabeled CVEs")
df_unlabeled.head(10)

import numpy as np

# CVSS v3.1 Base Score calculator
def cvss_base(av, ac, pr, ui, s, c, i, a):
    # Added 'ADJACENT_NETWORK' to the AV dictionary
    AV = {"NETWORK":0.85,"ADJACENT_NETWORK":0.62,"LOCAL":0.55,"PHYSICAL":0.2}[av]
    AC = {"LOW":0.77,"HIGH":0.44}[ac]
    PRU = {"NONE":0.85,"LOW":0.62,"HIGH":0.27}[pr]  # if Scope = Unchanged
    PRC = {"NONE":0.85,"LOW":0.68,"HIGH":0.5}[pr]   # if Scope = Changed
    UIv = {"NONE":0.85,"REQUIRED":0.62}[ui]
    Cia = {"NONE":0.0,"LOW":0.22,"HIGH":0.56}
    C_, I_, A_ = Cia[c], Cia[i], Cia[a]

    iss = 1 - (1-C_)*(1-I_)*(1-A_)
    if s=="UNCHANGED":
        impact = 6.42 * iss
        pr = PRU
    else:
        impact = 7.52*(iss-0.029) - 3.25*(iss-0.02)**15
        pr = PRC

    exploit = 8.22 * AV * AC * pr * UIv
    if impact <= 0: return 0.0
    base = (impact + exploit) if s=="UNCHANGED" else (1.08*(impact + exploit))
    return round(min(10, np.ceil(base*10)/10.0),1)

# Compute CVSS base scores for predicted vectors
df_unlabeled["CVSS_base_pred"] = df_unlabeled.apply(
    lambda r: cvss_base(r.AV, r.AC, r.PR, r.UI, r.S, r.C, r.I, r.A), axis=1
)

# Save updated dataset
df_unlabeled.to_csv("nvd_unlabeled_predicted.csv", index=False)

print("âœ… Added CVSS_base_pred column")
df_unlabeled.head(10)

# Compute CVSS base scores for predicted vectors
df_unlabeled["CVSS_base_pred"] = df_unlabeled.apply(
    lambda r: cvss_base(r.AV, r.AC, r.PR, r.UI, r.S, r.C, r.I, r.A), axis=1
)

# Save updated dataset
df_unlabeled.to_csv("nvd_unlabeled_predicted.csv", index=False)

print("âœ… Added CVSS_base_pred column")
display(df_unlabeled.head(10))

# Load labeled dataset again
df_labeled = pd.read_csv("nvd_labeled.csv")

# For consistency, rename true CVSS_base to CVSS_base_true
df_labeled = df_labeled.rename(columns={"CVSS_base": "CVSS_base_true"})

# For unlabeled, keep predicted base score
df_unlabeled = pd.read_csv("nvd_unlabeled_predicted.csv")

# Merge them
df_master = pd.concat([df_labeled, df_unlabeled], ignore_index=True)

# Fill unified CVSS_base column (true if available, else predicted)
df_master["CVSS_base_final"] = df_master["CVSS_base_true"].fillna(df_master.get("CVSS_base_pred"))

# Save master dataset
df_master.to_csv("nvd_master_complete.csv", index=False)

print("âœ… Master dataset created with no missing CVSS values")
print("Shape:", df_master.shape)
df_master.head(10)

import requests, gzip
import pandas as pd

# Download latest EPSS scores
epss_url = "https://epss.cyentia.com/epss_scores-current.csv.gz"
epss_file = "epss_scores-current.csv.gz"

with open(epss_file, "wb") as f:
    f.write(requests.get(epss_url).content)

# Load into DataFrame
epss_df = pd.read_csv(epss_file, compression="gzip", skiprows=1)

# Rename the first column to 'cve'
epss_df.rename(columns={epss_df.columns[0]: 'cve'}, inplace=True)


print("EPSS shape:", epss_df.shape)
display(epss_df.head())

# Merge with master dataset
df_master = pd.read_csv("nvd_master_complete.csv")
df_merged = df_master.merge(epss_df, left_on="cve_id", right_on="cve", how="left")

# Save merged dataset
df_merged.to_csv("nvd_master_with_epss.csv", index=False)

print("âœ… Merged EPSS scores into master dataset")
df_merged.head(10)

# Create normalized CVSS (0-1 scale)
df_merged["CVSS_norm"] = df_merged["CVSS_base_final"] / 10.0

# Weights
alpha, beta = 0.5, 0.5

# Compute PSSS
df_merged["PSSS"] = alpha * df_merged["CVSS_norm"] + beta * df_merged["epss"]

# Save updated dataset
df_merged.to_csv("nvd_master_with_psss.csv", index=False)

print("âœ… PSSS computed and saved")
df_merged[["cve_id","CVSS_base_final","epss","PSSS"]].head(10)

# Sort by PSSS (descending)
top_psss = df_merged.sort_values("PSSS", ascending=False).head(20)

print("ðŸ”¥ Top 20 CVEs by PSSS")
display(top_psss[["cve_id","CVSS_base_final","epss","PSSS"]])

import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
sc = plt.scatter(
    df_merged["CVSS_base_final"],
    df_merged["epss"],
    c=df_merged["PSSS"],
    cmap="plasma", alpha=0.7
)
plt.colorbar(sc, label="PSSS Score")
plt.xlabel("CVSS Base Score")
plt.ylabel("EPSS Probability")
plt.title("CVEs Prioritized by PSSS (Color = PSSS)")
plt.show()

attack_map_url = "https://raw.githubusercontent.com/center-for-threat-informed-defense/attack_to_cve/master/Att%26ckToCveMappings.csv"

attack_map = pd.read_csv(attack_map_url)
display(attack_map.head())

# Standardize column names
attack_map.rename(columns={"CVE ID": "cve_id"}, inplace=True)

# Combine technique columns into one list per CVE
def collect_techniques(row):
    techniques = []
    for col in ["Primary Impact","Secondary Impact","Exploitation Technique","Uncategorized"]:
        val = row[col]
        if pd.notna(val):
            techniques.extend([t.strip() for t in str(val).split(";")])
    return list(set(techniques))

attack_map["techniques"] = attack_map.apply(collect_techniques, axis=1)

# Keep only useful columns
attack_map = attack_map[["cve_id","techniques","Phase"]]
display(attack_map.head())

# Merge ATT&CK techniques into your master dataset
df_attack = df_merged.merge(attack_map, on="cve_id", how="left")

print("âœ… Added ATT&CK techniques to dataset")
display(df_attack[["cve_id","CVSS_base_final","epss","techniques","Phase"]].head(10))

# Define critical techniques â†’ tactics
critical_techniques = {
    "T1190":"Initial Access", "T1078":"Initial Access",
    "T1068":"Privilege Escalation", "T1574":"Privilege Escalation",
    "T1021":"Lateral Movement"
}

def is_critical(tech_list):
    if not isinstance(tech_list, list):
        return 0
    return any(t in critical_techniques for t in tech_list)

df_attack["attack_criticality"] = df_attack["techniques"].apply(is_critical)

print("âœ… Added attack_criticality flag")
display(df_attack[["cve_id","techniques","attack_criticality"]].head(15))

# Weights
alpha, beta, gamma = 0.4, 0.4, 0.2

# Normalize CVSS
df_attack["CVSS_norm"] = df_attack["CVSS_base_final"] / 10

# Compute final PSSS
df_attack["PSSS_final"] = (
    alpha * df_attack["CVSS_norm"].fillna(0) +
    beta * df_attack["epss"].fillna(0) +
    gamma * df_attack["attack_criticality"].fillna(0)
)

# Save enriched dataset
df_attack.to_csv("nvd_psss_with_attack.csv", index=False)

print("âœ… Final PSSS with ATT&CK context computed & saved")
display(df_attack[["cve_id","CVSS_base_final","epss","attack_criticality","PSSS_final"]].head(15))

import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
sc = plt.scatter(
    df_attack["CVSS_base_final"],
    df_attack["epss"],
    c=df_attack["PSSS_final"],
    cmap="viridis",
    alpha=0.7
)
plt.colorbar(sc, label="PSSS_final")
plt.xlabel("CVSS Base Score")
plt.ylabel("EPSS (Exploit Probability)")
plt.title("CVSS vs EPSS colored by PSSS_final")
plt.show()

top20 = df_attack.sort_values("PSSS_final", ascending=False).head(20)

plt.figure(figsize=(10,6))
plt.barh(top20["cve_id"], top20["PSSS_final"], color="orange")
plt.gca().invert_yaxis()
plt.xlabel("PSSS_final")
plt.title("Top 20 CVEs by Prioritized Security Scoring System (PSSS)")
plt.show()

import matplotlib.pyplot as plt

df_attack["PSSS_before"] = (df_attack["CVSS_base_final"]/10*0.5 + df_attack["epss"]*0.5)  # original formula before ATT&CK
df_sorted = df_attack.sort_values("PSSS_final", ascending=False)

plt.figure(figsize=(10,6))
plt.scatter(df_sorted["PSSS_before"], df_sorted["PSSS_final"], alpha=0.6, c='orange')
plt.xlabel("PSSS (before ATT&CK)")
plt.ylabel("PSSS_final (with ATT&CK)")
plt.title("Before vs After ATT&CK Boost on PSSS")
plt.plot([0,1],[0,1],'--',color='gray')
plt.show()

import matplotlib.pyplot as plt

# Calculate PSSS before ATT&CK
df_attack["PSSS_before"] = (df_attack["CVSS_base_final"]/10*0.5 + df_attack["epss"]*0.5)

# Sort by final PSSS
df_sorted = df_attack.sort_values("PSSS_final", ascending=False)

plt.figure(figsize=(12,8))
# This is the scatter plot where each point represents a CVE.
# The x-axis shows the PSSS score before considering ATT&CK techniques.
# The y-axis shows the final PSSS score after incorporating ATT&CK criticality.
# The color of the points is orange, and the transparency is set to 0.6.
plt.scatter(df_sorted["PSSS_before"], df_sorted["PSSS_final"], alpha=0.6, c='orange', label='CVEs')

plt.xlabel("PSSS (before ATT&CK)") # Label for the x-axis
plt.ylabel("PSSS_final (with ATT&CK)") # Label for the y-axis
plt.title("Before vs After ATT&CK Boost on PSSS") # Title of the plot

# This is a dashed gray line representing where PSSS_before equals PSSS_final.
# Points above this line have a higher PSSS_final, indicating they are more critical due to ATT&CK context.
# Points below this line have a lower PSSS_final, or their criticality was not significantly impacted by ATT&CK context in this model.
plt.plot([0,1],[0,1],'--',color='gray', label='PSSS_before = PSSS_final')

# Add labels (assuming 'CVE_ID' column exists)
for i, row in df_sorted.iterrows():
    plt.text(row["PSSS_before"]+0.005, row["PSSS_final"]+0.005, row["cve_id"], fontsize=8, alpha=0.7)

plt.legend() # Add legend
plt.show()

import matplotlib.pyplot as plt

# Calculate PSSS before ATT&CK if not already done
if "PSSS_before" not in df_attack.columns:
    df_attack["PSSS_before"] = (df_attack["CVSS_base_final"]/10*0.5 + df_attack["epss"]*0.5)

# Sort by final PSSS
df_sorted = df_attack.sort_values("PSSS_final", ascending=False)

# Select the top N CVEs for the plot
top_n = 20 # You can adjust this number
top_cves = df_sorted.head(top_n)

# Create a bar chart
fig, ax = plt.subplots(figsize=(12, 8))

bar_width = 0.35
index = range(top_n)

bars1 = ax.bar(index, top_cves["PSSS_before"], bar_width, label="PSSS (without ATT&CK mapping)", color="skyblue")
bars2 = ax.bar([i + bar_width for i in index], top_cves["PSSS_final"], bar_width, label="PSSS_final (with ATT&CK mapping)", color="green")

ax.set_xlabel("CVEs")
ax.set_ylabel("PSSS Score")
ax.set_title(f"Top {top_n} CVEs: PSSS Before and After ATT&CK Boost")
ax.set_xticks([i + bar_width / 2 for i in index])
ax.set_xticklabels(top_cves["cve_id"], rotation=90)
ax.legend()

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Select important columns
df_compare = df_attack[["cve_id", "CVSS_base_final", "epss", "PSSS_final"]].copy()

# Normalize CVSS to 0â€“1 scale (like EPSS & PSSS)
df_compare["CVSS_norm"] = df_compare["CVSS_base_final"] / 10

# Sort CVEs by PSSS (or choose any ordering you like)
df_plot = df_compare.sort_values("PSSS_final", ascending=False).head(20)

# Create bar positions
import numpy as np
index = np.arange(len(df_plot))

bar_width = 0.25

plt.figure(figsize=(14, 8))

# Bars for each score
plt.bar(index, df_plot["CVSS_norm"], bar_width, label="CVSS (normalized)", color="skyblue")
plt.bar(index + bar_width, df_plot["epss"], bar_width, label="EPSS", color="orange")
plt.bar(index + 2*bar_width, df_plot["PSSS_final"], bar_width, label="PSSS", color="green")

# Labels & layout
plt.xlabel("CVEs")
plt.ylabel("Score (0â€“1 scale)")
plt.title("Comparison of CVSS vs EPSS vs PSSS Prioritization for Top 20 CVEs")
plt.xticks(index + bar_width, df_plot["cve_id"], rotation=90)
plt.legend()
plt.tight_layout()
plt.show()
